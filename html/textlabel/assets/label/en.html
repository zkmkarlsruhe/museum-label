<h1><i>intelligent.museum</i></h1>
<p>Spoken Language Identification: An AI-assisted Museum Label</p>
<p>2020/2021</p>

<p>
<b>Meta Information</b></br>
Auto-adaptive, AI-supported museum label with language identification
</p>

<p>
<b>Software</b><br/>
Spoken Language Identification (machine learning: Tensorflow; speech dataset: Mozilla Common Voice)
</p>

<p>
<b>Hardware</b><br/>
Single board computer, screen (10"), lidar sensor, lavalier microphone
</p>

<h2>Description</h2>
<p>The intelligent.museum project team has developed a prototype of an AI-supported museum label for the exhibition space. It is intended to identify the native language from the spoken language of the exhibition visitors. In this way, work description and meta-information are automatically translated into the corresponding language.<p>
<p>Machine recognition of spoken language is not a trivial problem. To teach a machine to recognize sentences of a language perfectly, the entire spectrum of a language is needed. This requires absurd amounts of data. Since languages overlap acoustically, the more languages there are to distinguish from each other, the more difficult the task becomes. The task becomes even more difficult when different accents, age, gender and other characteristics that influence the vocal tract are considered. In initial experiments, the prototype of the AI-supported text label is able to distinguish seven languages (German, English, French, Spanish, Italian, Chinese, Russian) with an overall accuracy of 83%.</p>
<p>Until this prototype becomes a scalable solution for international museums, further development is necessary and solutions need to be implemented. This is the only way to guarantee the necessary robustness for exhibition operations.</p>