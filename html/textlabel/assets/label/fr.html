<h1><i>intelligent.museum</i></h1>
<p>Spoken Language Identification: An AI-assisted Museum Label</p>
<p>2020/2021</p>

<p>
<b>Méta-information</b></br>
Cartel auto-adaptatif, assisté par IA, avec identification de la langue
</p>

<p>
<b>Logiciel</b><br/>
Identification du langage parlé (outil d’apprentissage automatique : Tensorflow ; base de données vocale : Mozilla Common Voice)
</p>

<p>
<b>Matériel</b><br/>
Ordinateur à carte unique, écran (10"), capteur LiDAR, microphone Lavalier
</p>

<h2>Description</h2>
<p>L'équipe du projet intelligent.museum a développé un prototype de cartel assisté par IA pour les espaces d'exposition. Il est destiné à identifier la langue maternelle des visiteurs de l'exposition à partir de leur langue parlée. De cette façon, la description de l'œuvre et les méta-informations sont automatiquement traduites dans la langue correspondante.</p>
<p>La reconnaissance automatique de la langue parlée n'est pas un problème trivial. Pour apprendre à une machine à reconnaître parfaitement les phrases d'une langue donnée, il faut disposer de tout le spectre de cette langue. Cela nécessite des quantités astronomiques de données. Comme différentes langues se chevauchent sur le plan acoustique, plus il y a de langues à distinguer les unes des autres, plus la tâche devient difficile. Cette dernière devient encore plus difficile si l'on tient compte des différents accents, de l'âge, du sexe et d'autres caractéristiques qui influencent le canal vocal. Lors des premières expériences, le prototype de cartel assisté par IA est capable de distinguer sept langues différentes (allemand, anglais, français, espagnol, italien, chinois, russe) avec une précision globale de 83 %.</p>
<p>En attendant que ce prototype devienne une solution évolutive pour les musées internationaux, il est nécessaire de poursuivre le développement et trouver des solutions. C'est le seul moyen de garantir la robustesse nécessaire à l’opération des expositions.</p>